{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cd5e25-affc-4e26-93eb-db9cb6aefd5f",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "## Enunciado\n",
    "Genere tres conjuntos de datos de entrenamiento correspondientes al problema de las espirales anidadas de la práctica de python, uno de longitud 150, otro de 600 y un tercero de 3000. Genere un conjunto de test de longitud 10000. A partir de cada uno de los conjuntos de entrenamiento, entrene el árbol de decisión correspondiente y grafique las predicciones sobre el conjunto de test. Comente los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d643cb3-91b5-45b6-9568-3bd54c45acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Comunes import standardTree\n",
    "from Generadores import espirales\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264f7ae-539b-47b1-803c-7031f4ab6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = list(espirales(10000)[\"input\"])\n",
    "\n",
    "sizes = [150, 600, 3000]\n",
    "\n",
    "trainingSets = []\n",
    "for sz in sizes:\n",
    "    trainingSets.append(espirales(sz))\n",
    "\n",
    "classifiers = []\n",
    "for i in range(len(trainingSets)):\n",
    "    classifiers.append(standardTree())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6879a1-0b36-476c-b7a6-802c65dd72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos cada clasificador\n",
    "for i in range(3):\n",
    "    classifiers[i].fit(list(trainingSets[i][\"input\"]), list(trainingSets[i][\"output\"]))\n",
    "\n",
    "# Y plotteamos\n",
    "fig, axes = plt.subplots(2, 3, figsize = (15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Para cada clasificador\n",
    "for i, clf in enumerate(classifiers):\n",
    "    \n",
    "    # Predecimos sobre el conjunto de test\n",
    "    predicciones = clf.predict(testSet)\n",
    "\n",
    "    # Convertimos el conjunto de test a un array de numpy para poder filtrar mas facil\n",
    "    test_array = np.array(testSet)  \n",
    "    \n",
    "    # Filtramos sobre el array, aca \"predicciones == 0\" evalua a un array de true/false con la longitud de predicciones,\n",
    "    # luego test_array evaluado en ese array devuelve los elementos para los cuales predicciones == 0 es true.\n",
    "    clase0 = test_array[predicciones == 0]\n",
    "    clase1 = test_array[predicciones == 1]\n",
    "    \n",
    "    # Graficamos, donde clase0[:, 0] son los valores de x (pues nos quedamos con todas las filas pero solo la columna 0) y \n",
    "    # clase0[:, 1] son los valores de y.\n",
    "    axes[i].scatter(clase0[:, 0], clase0[:, 1], color='blue', s=1)\n",
    "    axes[i].scatter(clase1[:, 0], clase1[:, 1], color='orange', s=1)\n",
    "    \n",
    "    # Configurar gráfico\n",
    "    axes[i].set(xlabel='X', ylabel='Y', \n",
    "               title=f'Clasificador entrenado con {sizes[i]} datos')\n",
    "\n",
    "# Imprimimos los conjuntos de entrenamiento para visualizarlos\n",
    "for i, trainingSet in enumerate(trainingSets):\n",
    "\n",
    "    # De los puntos del training set que verifican que su output es 0, quedate con su input y mappeales la proyeccion en x/y\n",
    "    x0 = trainingSet[trainingSet[\"output\"] == 0][\"input\"].apply(lambda x: x[0])  \n",
    "    y0 = trainingSet[trainingSet[\"output\"] == 0][\"input\"].apply(lambda x: x[1]) \n",
    "\n",
    "    # De los puntos del training set que verifican que su output es 1, quedate con su input y mappeales la proyeccion en x/y\n",
    "    x1 = trainingSet[trainingSet[\"output\"] == 1][\"input\"].apply(lambda x: x[0]) \n",
    "    y1 = trainingSet[trainingSet[\"output\"] == 1][\"input\"].apply(lambda x: x[1]) \n",
    "\n",
    "    # Desplazamos el plot en 3 para plottear debajo del clasificador.\n",
    "    axes[i + 3].scatter(x0, y0, color=\"blue\", s=1, label=\"Class 0\")\n",
    "    axes[i + 3].scatter(x1, y1, color=\"orange\", s=1, label=\"Class 1\")\n",
    "\n",
    "    # Detalles del plot\n",
    "    axes[i + 3].set_xlabel('X')\n",
    "    axes[i + 3].set_ylabel('Y')\n",
    "    axes[i + 3].set_title(f'Conjunto de entrenamiento para\\n el clasificador con {sizes[i]} datos')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3861b4bd-f981-4b6a-a760-1e669faed858",
   "metadata": {},
   "source": [
    "### Comentarios sobre los resultados.\n",
    "\n",
    "Lo primero que podemos concluír es que, claramente, conforme aumenta el tamaño del conjunto de entrenamiento el clasificador obtiene un mejor desempeño sobre el conjunto de prueba. Si observamos las gráficas de los conjuntos de entrenamiento que generamos debajo de las predicciones de cada clasificador, podemos notar que para el caso de 150 datos la figura de la espiral no es reconocible. En ese caso, la muestra tomada no es representativa en absoluto de la población, entonces lo que el clasificador aprende está sobreajustado al conjunto de entrenamiento.\n",
    "\n",
    "Para el conjunto de 600 datos ya es posible reconocer la forma de las espirales, y esto se refleja en las predicciones de su clasificador asociado sobre el conjunto de test. Finalmente, el conjunto de entrenamiento de 3000 datos es en términos prácticos toda la población, por lo que el clasificador generaliza bien en su entrenamiento y obtiene un buen desempeño en el test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
