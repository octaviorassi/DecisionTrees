{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ce0c05-606f-45a7-ae51-f49b35772b8d",
   "metadata": {},
   "source": [
    "# Ejercicio 4 - Dimensionalidad\n",
    "Genere datasets con C = 0.78, n = 250 para el conjunto de entrenamiento y n = 10000 para el de test, variando esta vez el valor de d según la siguiente lista: 2, 4, 8, 16, 32. Para cada valor de d cree 20 conjuntos distintos de entrenamiento, y uno solo de test. Genere una gráfica del train y test error en función de d para el problema \"paralelo\" y el \"diagonal\" (todos en la misma gráfica). Discuta los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429b962-60d6-4353-9c5b-53d554798f7d",
   "metadata": {},
   "source": [
    "## Definición de funciones\n",
    "Comencemos por definir las funciones que nos serviran para el caso de diagonales y el caso de paralelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121aaca5-b28d-4ba7-a900-eb5211ae27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generadores import diagonales, paralelas\n",
    "from Comunes import standardTree\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9989a-8322-467f-8801-d15d47bfd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una funcion que dados los parametros y la lista de valores de d (dimensionalidad) genere la lista de training sets\n",
    "def generateTrainingSetsD(setCount, generator, C, n, dims):\n",
    "\n",
    "    # Inicializamos la lista de conjuntos de entrenamiento\n",
    "    trainingSets = [[] for _ in range(len(dims))]\n",
    "    \n",
    "    # Para cada valor de d\n",
    "    for i, d in enumerate(dims):\n",
    "\n",
    "        # Generamos setCount conjuntos de entrenamiento\n",
    "        for _ in range(setCount):\n",
    "            trainingSets[i].append(generator(n, d, C))\n",
    "            time.sleep(1)    \n",
    "\n",
    "    return trainingSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e294f07-075e-4a13-8f31-f3812d34f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La funcion para generar clasificadores es identica a la del ejercicio anterior, donde cValsCount es dimsCount\n",
    "def generateClassifiers(dimsCount, setCount, trainingSets):\n",
    "    # Creamos la lista de listas de clasificadores. La lista contiene dimsCount listas con setCount clasificadores cada una.\n",
    "    classifiers = [[] for _ in range(dimsCount)]\n",
    "    \n",
    "    # Creamos los clasificadores\n",
    "    for classifierList in classifiers:\n",
    "        for i in range(setCount):\n",
    "            classifierList.append(standardTree())\n",
    "    \n",
    "    # Entrenamos los clasificadores con su set de entrenamiento correspondiente.\n",
    "    for i,classifierList in enumerate(classifiers):\n",
    "        for j,classifier in enumerate(classifierList):\n",
    "            classifier.fit(list(trainingSets[i][j][\"Input\"]), list(trainingSets[i][j][\"Output\"]))\n",
    "\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3016a-dcd4-4e19-97bf-a0a00f2bd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve (trainingErrors, testErrors) como tupla.\n",
    "def getPerformanceStats(trainingSets, dimsCount, setCount, testsSet, classifiers):\n",
    "    # Creamos una lista de listas de errores. La lista contiene dimsCount listas con setCount elementos cada una, de manera que \n",
    "    # trainingErrors[i][j] es el error de entrenamiento para el classifier[i][j]. Lo mismo vale para testErrors.\n",
    "    # Esto sera la salida de nuestra funcion.\n",
    "    trainingErrors = [[] for _ in range(dimsCount)] \n",
    "    testErrors     = [[] for _ in range(dimsCount)] \n",
    "    \n",
    "    # Para cada lista de conjuntos de entrenamiento\n",
    "    for i in range(dimsCount):\n",
    "    \n",
    "        # Y para cada conjunto de entrenamientos dentro de la lista\n",
    "        for j in range(setCount):\n",
    "    \n",
    "            # Extraemos su clasificador asociado\n",
    "            classifier = classifiers[i][j]\n",
    "    \n",
    "            # Predecimos los outputs sobre el mismo conjunto de entrenamiento y calculamos su loss\n",
    "            trainingPredict = classifier.predict(list(trainingSets[i][j][\"Input\"]))\n",
    "            trainingLoss = zero_one_loss(trainingSets[i][j][\"Output\"], trainingPredict)\n",
    "    \n",
    "            trainingErrors[i].append(trainingLoss)\n",
    "    \n",
    "            # Predecimos los outputs sobre el conjunto de test y calculamos su loss\n",
    "            testPredict = classifier.predict(list(testsSet[i][\"Input\"]))\n",
    "            testLoss = zero_one_loss(testsSet[i][\"Output\"], testPredict)\n",
    "            \n",
    "            testErrors[i].append(testLoss)\n",
    "    \n",
    "    return (trainingErrors, testErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfecfee-ad28-407d-ac6d-95744da83417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotErrors(trainingErrorsDiagonales, testErrorsDiagonales, trainingErrorParalelas, testErrorsParalelas, dims):\n",
    "\n",
    "    meanTrainingErrorsDiagonales = [np.mean(errorList) for errorList in trainingErrorsDiagonales]\n",
    "    meanTestErrorsDiagonales     = [np.mean(errorList) for errorList in testErrorsDiagonales]\n",
    "        \n",
    "    meanTrainingErrorsParalelas = [np.mean(errorList) for errorList in trainingErrorsParalelas]\n",
    "    meanTestErrorsParalelas     = [np.mean(errorList) for errorList in testErrorsParalelas]\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "        \n",
    "    # Graficamos error de entrenamiento contra error de testeo para diagonales\n",
    "    plt.plot(dims, meanTrainingErrorsDiagonales, color=\"blue\", marker='o', linestyle='-', linewidth=2, markersize=8, label='Error de entrenamiento diagonales')\n",
    "    plt.plot(dims, meanTestErrorsDiagonales, color=\"orange\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo diagonales')\n",
    "    \n",
    "    # Y para paralelas\n",
    "    plt.plot(dims, meanTrainingErrorsParalelas, color=\"purple\", marker='o', linestyle='-', linewidth=2, markersize=8, label='Error de entrenamiento paralelas')\n",
    "    plt.plot(dims, meanTestErrorsParalelas, color=\"yellow\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo paralelas')\n",
    "    \n",
    "    plt.xlabel(\"Dimensionalidad\", fontsize=12)\n",
    "    plt.ylabel(\"Tasa de error\", fontsize=12)\n",
    "    plt.title(\"Error de entrenamiento vs Error de testeo\", fontsize=14)\n",
    "    plt.grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    # Marcamos los tamaños adecuados en el eje X\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(dims)  \n",
    "    ax.get_xaxis().set_major_formatter(plt.ScalarFormatter()) # Esto cambia los numeros a notacion normal y no cientifica\n",
    "    ax.tick_params(axis='x', which='minor', bottom=False)     # Esconde los ticks del eje que no son relevantes\n",
    "    \n",
    "    # Y setteamos los valores del eje Y para que matcheen con nuestros resultados\n",
    "    ax.set_yticks(np.round(sorted(set(meanTrainingErrorsParalelas + meanTestErrorsParalelas + meanTrainingErrorsDiagonales + meanTestErrorsDiagonales)), decimals=2))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75b9f9-2e4d-4616-b5d5-dd121bc24ccc",
   "metadata": {},
   "source": [
    "## Definición de parámetros y clasificadores\n",
    "Pasemos ahora a utilizar las funciones previamente definidas para generar los datos necesarios para entrenar a los distintos clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168df3a-ff10-4b1c-84da-8faa80aee1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los parametros\n",
    "dims = [2, 4, 8, 16, 32]\n",
    "ntrain = 250\n",
    "ntest = 10000\n",
    "cval = 0.78\n",
    "\n",
    "setCount = 20\n",
    "dimsCount = len(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437654a8-3d1a-4515-b521-24cfd30a94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de test para diagonales.\n",
    "testSetsDiagonales = []\n",
    "\n",
    "for d in dims:\n",
    "    testSetsDiagonales.append(diagonales(ntest,d,cval))\n",
    "    time.sleep(1)\n",
    "\n",
    "trainingSetsDiagonales = generateTrainingSetsD(setCount, diagonales, cval, ntrain, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd9555-47e9-42f2-a757-a18ca81a6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonalClassifiers = generateClassifiers(dimsCount, setCount, trainingSetsDiagonales)\n",
    "trainingErrorsDiagonales, testErrorsDiagonales = getPerformanceStats(trainingSetsDiagonales, dimsCount, setCount, testSetsDiagonales, diagonalClassifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7e71a-7808-4af4-90a9-ce9892648969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de test para paralelas.\n",
    "testSetsParalelas = []\n",
    "\n",
    "for d in dims:\n",
    "    testSetsParalelas.append(paralelas(ntest,d,cval))\n",
    "    time.sleep(1)\n",
    "\n",
    "trainingSetsParalelas = generateTrainingSetsD(setCount, paralelas, cval, ntrain, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877dcff0-5265-47cd-b05c-8dd39a1ed48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelClassifiers = generateClassifiers(dimsCount, setCount, trainingSetsParalelas)\n",
    "trainingErrorsParalelas, testErrorsParalelas = getPerformanceStats(trainingSetsParalelas, dimsCount, setCount, testSetsParalelas, parallelClassifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98841efc-b0f2-4876-a75e-e0d404d42908",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotErrors(trainingErrorsDiagonales, testErrorsDiagonales, trainingErrorsParalelas, testErrorsParalelas, dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2dffa-1e00-47f9-93fa-eba18bf48638",
   "metadata": {},
   "source": [
    "## Comentarios sobre los resultados\n",
    "Primero analicemos lo que podemos ver de las gráficas. Para el caso de los errores de entrenamiento, podemos ver que ambos errores se mantienen en un rango de valores bastante similiares. También, podemos observar que el error de entrenamiento para el problema de las diagonales es más consistente, mientras que para el problema de de las paralelas el error muestra una tendencia decreciente.\n",
    "\n",
    "Por otro lado, para los casos de errores de testeo, podemos notar que para el problema de las paralelas los valores se mantienen bastante consistentes con un sutil crecimiento a medida que aumentamos la dimensionalidad. Pero para el problema de las diagonales el crecimiento es mucho más notorio y partir de dimensiones mayores a 4 el error es significativamente mayor al error de testeo para paralelas.\n",
    "\n",
    "Analicemos a qué se debe el crecimiento abrupto del error de testeo para el problema de las diagonales. Lo primero que tenemos que analizar es como se construye el árbol clasificador. Independientemente de la dimensión en la que estemos trabajando, el procedimiento que sigue nuestro clasificador es:\n",
    "- Seleccionar una componente $x_i$.\n",
    "- Escoger un valor $k$ para dividir a los datos en aquellos que verifican $x_i \\le k$ y aquellos que no.\n",
    "\n",
    "O sea, nuestro clasificador genera una especie de \"corte\" en alguna de las dimensiones de los datos.\n",
    "\n",
    "Analicemos por ejemplo los resultados del ejercicio 2, donde trabajamos con estas distribuciones en dimensión 2. Para ambos casos la solución óptima es una recta: en el caso del problema de las paralelas es una vertical y en el caso de las diagonales una que está inclinada. \n",
    "\n",
    "El clasificador para el caso de las paralelas consigue aproximar muy bien a esta solución debido a la naturaleza de las preguntas del árbol. La solución óptima, que es una recta vertical, puede ser descrita perfectamente con preguntas sobre el atributo $x_0$.\n",
    "\n",
    "En cambio, el problema de describir una recta con inclinación únicamente a través de desigualdades sobre $x$ e $y$ es irresoluble con una cantidad finita de preguntas. Es decir, la solución óptima no es siquiera alcanzable por como se construyen los arboles de decisión. Lo mejor que puede lograrse es una línea escalonada que aproxime a la recta buscada, y que clasificará mejor cuantos mas escalones tenga (es decir, cuanto mas parecida a la recta inclinada es). Esto puede observarse en las gráficas de la cantidad de nodos de los árboles del ejercicio 2 para ambos problemas: mientras que el problema de las paralelas encuentra un pico alrededor del tamaño 1000 y luego su cantidad de nodos decrece bruscamente (pues deja de sobreajustar al conjunto de entrenamiento), el problema de las diagonales también decrece pero se estabiliza a un valor mucho mas alto.\n",
    "\n",
    "Retomemos ahora el análisis sobre el problema de clasificar puntos de dimensión $n$. Lo que buscamos ahora es describir un hiperplano que separe ambas clases a través de preguntas del tipo \"es $x_i \\le k$?\". Aquí es donde el problema de las diagonales se complejiza significativamente. Si bien ya era imposible describir la recta inclinada en dos dimensiones, la cantidad de preguntas necesarias para aproximarnos al hiperplano óptimo crece exponencialmente conforme incrementa la dimensión de los datos. El problema es que la cantidad de preguntas que podemos realizar es finita, y un *split* solo puede realizarse si la ganancia de información es lo suficientemente alta, por lo que existe un límite a cuan cercano al hiperplano óptimo puede ser la frontera descrita por el árbol que construiremos.\n",
    "\n",
    "En cambio, el problema de las paralelas no se ve afectado por el aumento en la dimensionalidad. El hiperplano buscado sigue pudiendo ser representado perfectamente por una única pregunta sobre el valor de la primer componente de cada dato, el clasificador solo debe aprender valor de *k* óptimo para ello."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
