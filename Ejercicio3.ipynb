{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86af3884-7d7c-4246-adb9-13516d0acbd1",
   "metadata": {},
   "source": [
    "# Ejercicio 3 - Resistencia al ruido.\n",
    "## Enunciado.\n",
    "\n",
    "Genere datasets con d = 5, n = 250 para el conjunto de entrenamiento y n = 10000 para el de test, variando el valor de C (overlapping de las clases) de 0.5 a 2.5 con incrementos de 0.5. Como en el punto anterior, para cada valor dado de C cree 20 conjuntos distintos de entrenamiento, pero uno solo de test. Genere una gráfica del test-error en función de C para el problema \"paralelo\" y el \"diagonal\" (sólo los promedios de los 20 conjuntos para cada valor de C).\n",
    "\n",
    "También incluya en la gráfica los valores mínimos que se piden en el opcional 3.1 (el que no haga el opcional los puede pedir a la catedra). Todos los resultados de los dos problemas y el error mínimo en la misma gráfica. Discuta los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b165e-4c62-4342-92e1-8a75f5c3dec6",
   "metadata": {},
   "source": [
    "## Definición de funciones\n",
    "Comencemos por definir las funciones que nos serviran para el caso de diagonales y el caso de paralelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54402419-61d4-4e12-8cdd-8a162d9429d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generadores import diagonales, paralelas\n",
    "from Comunes import standardTree\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dad098-3164-47c7-82e6-4e266293875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una funcion que dados los parametros y la lista de valores de C genere la lista de training sets\n",
    "def generateTrainingSetsC(setCount, generator, d, n, cvals):\n",
    "\n",
    "    # Inicializamos la lista de conjuntos de entrenamiento\n",
    "    trainingSets = [[] for _ in range(len(cvals))]\n",
    "    \n",
    "    # Para cada valor de C\n",
    "    for i, C in enumerate(cvals):\n",
    "\n",
    "        # Generamos setCount conjuntos de entrenamiento de tamaño n\n",
    "        for _ in range(setCount):\n",
    "            trainingSets[i].append(generator(n, d, C))\n",
    "            time.sleep(1)    \n",
    "\n",
    "    return trainingSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa57957-730c-49bd-9223-90608ae03d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La funcion para generar clasificadores es identica a la del ejercicio anterior, donde setSizesCount es cValsCount\n",
    "def generateClassifiers(cValsCount, setCount, trainingSets):\n",
    "    # Creamos la lista de listas de clasificadores. La lista contiene setSizesCount listas con setCount clasificadores cada una.\n",
    "    classifiers = [[] for _ in range(cValsCount)]\n",
    "    \n",
    "    # Creamos los clasificadores\n",
    "    for classifierList in classifiers:\n",
    "        for i in range(setCount):\n",
    "            classifierList.append(standardTree())\n",
    "    \n",
    "    # Entrenamos los clasificadores con su set de entrenamiento correspondiente.\n",
    "    for i,classifierList in enumerate(classifiers):\n",
    "        for j,classifier in enumerate(classifierList):\n",
    "            classifier.fit(list(trainingSets[i][j][\"Input\"]), list(trainingSets[i][j][\"Output\"]))\n",
    "\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b38c5-7b7c-479a-8b8b-cb7771df12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve testErrors como tupla.\n",
    "def getPerformanceStats(cValsCount, setCount, testSets, classifiers):\n",
    "    # Creamos una lista de listas de errores. La lista contiene cValsCount listas con setCount elementos cada una, de manera que \n",
    "    # testError[i][j] es el error de test para el classifier[i][j].\n",
    "    \n",
    "    # Esto sera la salida de nuestra funcion.\n",
    "    testErrors     = [[] for _ in range(cValsCount)] \n",
    "    \n",
    "    # Para cada lista de conjuntos de entrenamiento\n",
    "    for i in range(cValsCount):\n",
    "    \n",
    "        # Y para cada conjunto de entrenamientos dentro de la lista\n",
    "        for j in range(setCount):\n",
    "    \n",
    "            # Extraemos su clasificador asociado\n",
    "            classifier = classifiers[i][j]\n",
    "    \n",
    "            # Predecimos los outputs sobre el conjunto de test y calculamos su loss\n",
    "            testPredict = classifier.predict(list(testSets[i][\"Input\"]))\n",
    "            testLoss = zero_one_loss(testSets[i][\"Output\"], testPredict)\n",
    "            \n",
    "            testErrors[i].append(testLoss)\n",
    "    \n",
    "    return testErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31d0e8-bccf-4069-bbe1-ee0447bc97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotErrors(testErrors, cVals):\n",
    "    \n",
    "    # Una vez calculados los errores y cantidad de nodos para cada par de clasificador y conjunto de entrenamiento, tomamos las medias\n",
    "    meanTestErrors     = [np.mean(errorList) for errorList in testErrors]\n",
    "    \n",
    "    plt.figure(figsize = (10, 4))\n",
    "    \n",
    "    # Graficamos error de testeo\n",
    "    plt.plot(cVals, meanTestErrors, color=\"orange\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo diagonal')\n",
    "    plt.xlabel(\"Varianza C\", fontsize=12)\n",
    "    plt.ylabel(\"Tasa de error\", fontsize=12)\n",
    "    plt.title(\"Error de testeo\", fontsize=14)\n",
    "    plt.grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    # Marcamos los tamaños adecuados en el eje X\n",
    "    axes = plt.gca()\n",
    "    axes.set_xticks(cVals)  \n",
    "    axes.get_xaxis().set_major_formatter(plt.ScalarFormatter()) # Esto cambia los numeros a notacion normal y no cientifica\n",
    "    axes.tick_params(axis='x', which='minor', bottom=False)     # Esconde los ticks del eje que no son relevantes\n",
    "    \n",
    "    # Y setteamos los valores del eje Y para que matcheen con nuestros resultados\n",
    "    axes.set_yticks(np.round(sorted(set(meanTestErrors)), decimals=2))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d1a2e-19ac-4e6e-92be-0ead1f1bd46a",
   "metadata": {},
   "source": [
    "## Definición de parámetros y clasificadores\n",
    "Pasemos ahora a utilizar las funciones previamente definidas para generar los datos necesarios para entrenar a los distintos clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507cad7-3ce7-4438-b0dc-74782783ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los parametros\n",
    "d = 5\n",
    "ntrain = 250\n",
    "ntest = 10000\n",
    "cvals = [0.5, 1, 1.5, 2, 2.5]\n",
    "\n",
    "setCount = 20\n",
    "cValsCount = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab69878-5d28-4785-a5ed-ab347bcf8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de test para diagonales.\n",
    "testSetsDiagonales = []\n",
    "\n",
    "for cval in cvals:\n",
    "    testSetsDiagonales.append(diagonales(ntest,d,cval))\n",
    "    time.sleep(1)\n",
    "\n",
    "trainingSetsDiagonales = generateTrainingSetsC(setCount, diagonales, d, ntrain, cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7a672-6710-4013-8cb5-8910548e6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonalClassifiers = generateClassifiers(cValsCount, setCount, trainingSetsDiagonales)\n",
    "\n",
    "testErrorsDiagonales = getPerformanceStats(cValsCount, setCount, testSetsDiagonales, diagonalClassifiers)\n",
    "\n",
    "plotErrors(testErrorsDiagonales, cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9398ad-6514-467d-8380-82252e21c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos de test para paralelas.\n",
    "testSetsParalelas = []\n",
    "\n",
    "for cval in cvals:\n",
    "    testSetsParalelas.append(paralelas(ntest,d,cval))\n",
    "    time.sleep(1)\n",
    "\n",
    "trainingSetsParalelas = generateTrainingSetsC(setCount, paralelas, d, ntrain, cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a6513-7f3e-48ad-9a0a-1cde54c13f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paralelasClassifiers = generateClassifiers(cValsCount, setCount, trainingSetsParalelas)\n",
    "\n",
    "testErrorsParalelas = getPerformanceStats(cValsCount, setCount, testSetsParalelas, paralelasClassifiers)\n",
    "\n",
    "plotErrors(testErrorsParalelas, cvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987fe2f-6d45-4393-88f2-d72050c6620e",
   "metadata": {},
   "source": [
    "## Ejercicio 3.1 - Curva de error mínimo\n",
    "Puede calcular para cada valor de C cuál es el mínimo error que se puede conseguir? Cómo se comparan dichos valores con los obtenidos con el árbol? Obtenga una curva de error mínimo y agréguela a la gráfica anterior. Explique brevemente cómo obtuvo los valores mínimos.\n",
    "Hay varias maneras de hacerlo. Una simple es imaginando cuál es el clasificador ideal o de mínimo error para este problema (a ese clasificador se lo llama \"clasificador de Bayes\") y midiendo directamente sobre un conjunto de test grande (10000 puntos para d=5) cuántos puntos son mal clasificados por ese clasificador ideal. Para que verifiquen sus resultados, el error de Bayes para el diagonal con C=1.00 es 15.86%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165f7ff-5c2a-41ce-9bf8-4104261aec6d",
   "metadata": {},
   "source": [
    "## Resolución\n",
    "Comencemos por construírnos los clasificadores de bayes para cada generador. La idea será, dado que conocemos los parámetros de las distribuciones normales que utilizan tanto paralelas como diagonales, crearnos dos clasificadores que dado un input calculan la probabilidad de que ese punto haya sido generado por cada una de las distribuciones y lo asignan a la clase que sea mas probable.\n",
    "\n",
    "Definimos una función general *bayesClassifier* que construye el clasificador que describimos, asumiendo que se trata de un problema de clasificación binario donde las clases comparten el desvío estandar y tienen distintas medias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623b70e-ba10-4c90-ba20-2b56cd577f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificador de Bayes para un problema de clasificacion binario, en donde tenemos\n",
    "# dos distribuciones definidas por sus medias y un desvío estandar común a las dos.\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def bayesClassifier(data, meanClass0, meanClass1, standardDeviation):\n",
    "\n",
    "    # Todos los puntos en data tienen la misma dimension\n",
    "    d = len(data[0])\n",
    "\n",
    "    covarianceMatrix = np.eye(d) * (standardDeviation ** 2)\n",
    "\n",
    "    distributionClass0 = multivariate_normal(mean=meanClass0, cov=covarianceMatrix)\n",
    "    distributionClass1 = multivariate_normal(mean=meanClass1, cov=covarianceMatrix)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for point in data:\n",
    "\n",
    "        # Calculo la probabilidad respecto de ambas distribuciones\n",
    "        probClass0 = distributionClass0.pdf(point)\n",
    "        probClass1 = distributionClass1.pdf(point)\n",
    "\n",
    "        if (probClass0 >= probClass1):\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(1)\n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78fd32-e835-4272-901d-f0937fa98ad3",
   "metadata": {},
   "source": [
    "Ahora, definimos el clasificador de bayes para cada uno de los generadores pasandole sus parámetros a *bayesClassifier*,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30704420-90f8-4676-a0e4-f1c260f6e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesClassifierParallel(data, C):\n",
    "    d = len(data[0])\n",
    "    meanClass0 = np.full(d,0)\n",
    "    meanClass0[0] = 1\n",
    "    \n",
    "    meanClass1 = np.full(d, 0)\n",
    "    meanClass1[0] = -1\n",
    "    \n",
    "    return bayesClassifier(data, meanClass0, meanClass1, C * np.sqrt(d))\n",
    "    \n",
    "def bayesClassifierDiagonal(data, C):\n",
    "    d = len(data[0])\n",
    "    return bayesClassifier(data, np.full(d,-1), np.full(d,1), C * np.sqrt(d))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc692127-95b5-41d6-bde2-5b5432c2bfff",
   "metadata": {},
   "source": [
    "Calculamos el error de bayes para cada uno como el error del clasificador de bayes sobre un conjunto mas grande que el que usaremos para testear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd7ccb-4f1c-4605-b0d7-cdb775e6d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesErrorsDiagonal = []\n",
    "for cval in cvals:\n",
    "\n",
    "    testSet     = diagonales(ntest * 10, d, cval)\n",
    "    testPredict = bayesClassifierDiagonal(list(testSet[\"Input\"]), cval)\n",
    "    testLoss    = zero_one_loss(testSet[\"Output\"], testPredict)\n",
    "\n",
    "    bayesErrorsDiagonal.append(testLoss)\n",
    "    \n",
    "    print(f\"C = {cval} -> error = {testLoss}\")\n",
    "\n",
    "bayesErrorsParallel = []\n",
    "for cval in cvals:\n",
    "\n",
    "    testSet     = paralelas(ntest * 10, d, cval)\n",
    "    testPredict = bayesClassifierParallel(list(testSet[\"Input\"]), cval)\n",
    "    testLoss    = zero_one_loss(testSet[\"Output\"], testPredict)\n",
    "\n",
    "    bayesErrorsParallel.append(testLoss)\n",
    "    \n",
    "    print(f\"C = {cval} -> error = {testLoss}\")\n",
    "\n",
    "# Observacion: dan igual. Sabiendo la distribución, el problema de clasificar los datos de paralelas() y de diagonales() es el mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2faa6-01fa-4717-9339-726c66e90f73",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "Veamos ahora en una misma gráfica ambas curvas de error junto con sus errores de bayes asociados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01442ccb-9fc3-44ce-86b7-4e214b9d1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez calculados los errores y cantidad de nodos para cada par de clasificador y conjunto de entrenamiento, tomamos las medias\n",
    "meanTestErrorsDiagonales     = [np.mean(errorList) for errorList in testErrorsDiagonales]\n",
    "meanTestErrorsParalelas      = [np.mean(errorList) for errorList in testErrorsParalelas]\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "# Graficamos error de testeo para cada generador\n",
    "plt.plot(cvals, meanTestErrorsDiagonales, color=\"orange\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo diagonal')\n",
    "plt.plot(cvals, meanTestErrorsParalelas, color=\"blue\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo paralelas')\n",
    "\n",
    "# Y los errores de bayes para cada cval\n",
    "plt.scatter(cvals, bayesErrorsDiagonal, color=\"red\", marker='o', s=100, \n",
    "            edgecolor='black', alpha=0.7, zorder=3)\n",
    "\n",
    "# No lo ploteamos porque es igual.\n",
    "# plt.scatter(cvals, bayesErrorsParallel, color = \"blue\") \n",
    "\n",
    "\n",
    "plt.xlabel(\"Varianza C\", fontsize=12)\n",
    "plt.ylabel(\"Tasa de error\", fontsize=12)\n",
    "plt.title(\"Error de testeo\", fontsize=14)\n",
    "plt.grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Marcamos los tamaños adecuados en el eje X\n",
    "axes = plt.gca()\n",
    "axes.set_xticks(cvals)  \n",
    "axes.get_xaxis().set_major_formatter(plt.ScalarFormatter()) # Esto cambia los numeros a notacion normal y no cientifica\n",
    "axes.tick_params(axis='x', which='minor', bottom=False)     # Esconde los ticks del eje que no son relevantes\n",
    "\n",
    "# Y setteamos los valores del eje Y para que matcheen con nuestros resultados\n",
    "axes.set_yticks(np.round(sorted(set(meanTestErrorsDiagonales + meanTestErrorsParalelas + bayesErrorsDiagonal)), decimals=2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae334bd-14dd-42e4-9d2c-0d75add08e01",
   "metadata": {},
   "source": [
    "Notemos que el comportamiento para ambos problemas es el mismo. Conforme aumenta la varianza, el desempeño de los clasificadores empeora. Esto se sustenta también por el aumento del error de bayes, podemos ver que incluso el clasificador ideal toma valores de error cada vez mas altos cuando la varianza aumenta.\n",
    "\n",
    "Intuitivamente, un aumento en la varianza produce mayor superposición en los puntos de cada clase, por lo que los límites se vuelven mas difusos. Al aumentar la superposición, el error que se produce por tomar decisiones estadísticas inevitablemente aumenta, pues la cantidad (y por ende la proporción) de datos afectados por estas decisiones es mayor. Incluso el clasificador ideal etiquetará incorrectamente al menos a la mitad de los puntos de la intersección, por lo que cuando la cantidad de puntos en la intersección crece, la tasa de error también. \n",
    "\n",
    "*Observación.* Notemos que la noción de intersección no está tan clara al hablar de distribuciones de probabilidad, pero podemos interpretarla como la región del espacio donde ambas distribuciones asignan una densidad o probabilidad significativa. Es decir, son los puntos que tienen una probabilidad no despreciable de ser generados por cualquiera de las dos distribuciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
