{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c084074b-d756-4a08-b214-53105a949921",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "## Enunciado\n",
    "Genere datasets usando el código \"diagonal\" desarrollado en la práctica de python (el otro conjunto desarrollado se llama \"paralelo\"), con C = 0.78 y d = 2. Genere un único conjunto de test con n = 10000. Genere 20 conjuntos de entrenamiento para cada uno de los siguientes valores de n: 125, 250, 500, 1000, 2000, 4000. Entrene árboles sobre estos conjuntos y guarde los resultados de error (1-accuracy) sobre los datos de entrenamiento y sobre el conjunto de test, como así también el tamaño del árbol (atributo tree_.node_count). En primer lugar genera una gráfica de las predicciones sobre los datos de test (plot x-y con colores para las clases) para un ejemplo de cada tamaño de conjunto de entrenamiento. Comente lo que se puede observar.\n",
    "\n",
    "También genere dos gráficas: la primer gráfica tiene el training error y test error, y la segunda la cantidad de nodos en el árbol, todos como función de la longitud del conjunto de entrenamiento (utilice siempre el promedio de los 20 conjuntos de cada longitud dada). Sugerencia: usar escala logarítmica en el eje x, de la cantidad de datos.\n",
    "\n",
    "Finalmente, repita todo el procedimiento completo usando como generador de datos el \"paralelo\". Incluya los resultados correspondientes en las mismas gráficas del diagonal. Discuta los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a02ce1-3ed7-4d25-b680-96e53fdd3e7e",
   "metadata": {},
   "source": [
    "## Resolucion \n",
    "### Caso diagonales.\n",
    "Comencemos por generar los conjuntos de entrenamiento y los clasificadores para luego entrenarlos. Definimos una funcion general que dado un generador de puntos (como diagonales o paralelas) genera los conjuntos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a4fa7-beac-437f-8744-8422756be02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from Generadores import diagonales, paralelas\n",
    "from Comunes import standardTree\n",
    "from sklearn.metrics import zero_one_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e93835-158d-4e94-95d3-f231928c8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainingSets(setSizes, setCount, generator, d, C):\n",
    "\n",
    "    # Inicializamos la lista de conjuntos de entrenamiento\n",
    "    trainingSets = [[] for _ in range(len(setSizes))]\n",
    "    \n",
    "    # Para cada tamaño de conjunto\n",
    "    for i, setSize in enumerate(setSizes):\n",
    "\n",
    "        # Generamos setCount conjuntos de entrenamiento\n",
    "        for _ in range(setCount):\n",
    "            trainingSets[i].append(generator(setSize, d, C))\n",
    "            time.sleep(1)    \n",
    "\n",
    "    return trainingSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7d687-16d6-4dcf-af47-2647cffcce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClassifiers(setSizesCount, setCount, trainingSets):\n",
    "    # Creamos la lista de listas de clasificadores. La lista contiene setSizesCount listas con setCount clasificadores cada una.\n",
    "    classifiers = [[] for _ in range(setSizesCount)]\n",
    "    \n",
    "    # Creamos los clasificadores\n",
    "    for classifierList in classifiers:\n",
    "        for i in range(setCount):\n",
    "            classifierList.append(standardTree())\n",
    "    \n",
    "    # Entrenamos los clasificadores con su set de entrenamiento correspondiente.\n",
    "    for i,classifierList in enumerate(classifiers):\n",
    "        for j,classifier in enumerate(classifierList):\n",
    "            classifier.fit(list(trainingSets[i][j][\"Input\"]), list(trainingSets[i][j][\"Output\"]))\n",
    "\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e76c26-f984-4d66-8483-357900f23861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devuelve (trainingErrors, testErrors, treeSizes) como tupla.\n",
    "def getPerformanceStats(trainingSets, setSizesCount, setCount, testSet, classifiers):\n",
    "    # Creamos una lista de listas de errores y tamaños de los arboles. La lista contiene setSizesCount listas con setCount elementos cada una, de manera que \n",
    "    # trainingErrors[i][j] es el error de entrenamiento para el classifier[i][j]. Lo mismo vale para testErrors y treeSizes.\n",
    "    # Esto sera la salida de nuestra funcion.\n",
    "    trainingErrors = [[] for _ in range(setSizesCount)] \n",
    "    testErrors     = [[] for _ in range(setSizesCount)] \n",
    "    treeSizes      = [[] for _ in range(setSizesCount)] \n",
    "    \n",
    "    # Para cada lista de conjuntos de entrenamiento\n",
    "    for i in range(setSizesCount):\n",
    "    \n",
    "        # Y para cada conjunto de entrenamientos dentro de la lista\n",
    "        for j in range(setCount):\n",
    "    \n",
    "            # Extraemos su clasificador asociado\n",
    "            classifier = classifiers[i][j]\n",
    "    \n",
    "            # Predecimos los outputs sobre el mismo conjunto de entrenamiento y calculamos su loss\n",
    "            trainingPredict = classifier.predict(list(trainingSets[i][j][\"Input\"]))\n",
    "            trainingLoss = zero_one_loss(trainingSets[i][j][\"Output\"], trainingPredict)\n",
    "    \n",
    "            trainingErrors[i].append(trainingLoss)\n",
    "    \n",
    "            # Predecimos los outputs sobre el conjunto de test y calculamos su loss\n",
    "            testPredict = classifier.predict(list(testSet[\"Input\"]))\n",
    "            testLoss = zero_one_loss(testSet[\"Output\"], testPredict)\n",
    "            \n",
    "            testErrors[i].append(testLoss)\n",
    "    \n",
    "            # Y agragamos la cantidad de nodos del arbol.\n",
    "            treeSizes[i].append(classifier.tree_.node_count)\n",
    "\n",
    "    return (trainingErrors, testErrors, treeSizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbac87-4ea6-4ede-885a-582c94ba2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerSize(trainingSets, classifiers, testSet, setSizes):\n",
    "\n",
    "    testSet = list(testSet[\"Input\"])\n",
    "    fig, axes = plt.subplots(2, 3, figsize = (14, 8))\n",
    "    axes = axes.flatten()\n",
    "    for i, trainingSet in enumerate(trainingSets):\n",
    "    \n",
    "        # Predecimos sobre el conjunto de testeo\n",
    "        predict = classifiers[i].predict(testSet)\n",
    "    \n",
    "        # Nos quedamos con las componentes de los clase 0\n",
    "        x0 = np.array([e[0] for (i,e) in enumerate(testSet) if predict[i] == 0])\n",
    "        y0 = np.array([e[1] for (i,e) in enumerate(testSet) if predict[i] == 0])\n",
    "    \n",
    "        # Y las componentes de los clase 1\n",
    "        x1 = np.array([e[0] for (i,e) in enumerate(testSet) if predict[i] == 1])\n",
    "        y1 = np.array([e[1] for (i,e) in enumerate(testSet) if predict[i] == 1])\n",
    "    \n",
    "        # Y plotteamos en el subplot correspondiente\n",
    "        axes[i].scatter(x0, y0, color = \"blue\", s = 1)\n",
    "        axes[i].scatter(x1, y1, color = \"orange\", s = 1)\n",
    "    \n",
    "        # Detalles del plot\n",
    "        axes[i].set_xlabel('X')\n",
    "        axes[i].set_ylabel('Y')\n",
    "        axes[i].set_title(f'Clasificador entrenado con {setSizes[i]} datos')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43b62b-3028-45d1-a37a-f1a53b56eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotErrors(trainingErrors, testErrors, treeSizes, setSizes):\n",
    "    \n",
    "    # Una vez calculados los errores y cantidad de nodos para cada par de clasificador y conjunto de entrenamiento, tomamos las medias\n",
    "    meanTrainingErrors = [np.mean(errorList) for errorList in trainingErrors]\n",
    "    meanTestErrors     = [np.mean(errorList) for errorList in testErrors]\n",
    "    meanTreeSizes      = [np.mean(sizeList)  for sizeList in treeSizes]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize = (15, 4))\n",
    "    \n",
    "    # Graficamos error de entrenamiento contra error de testeo\n",
    "    axes[0].plot(setSizes, meanTrainingErrors, color=\"blue\", marker='o', linestyle='-', linewidth=2, markersize=8, label='Error de entrenamiento')\n",
    "    axes[0].plot(setSizes, meanTestErrors, color=\"orange\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo')\n",
    "    axes[0].set_xlabel(\"Tamaño del conjunto de entrenamiento\", fontsize=12)\n",
    "    axes[0].set_ylabel(\"Tasa de error\", fontsize=12)\n",
    "    axes[0].set_title(\"Error de entrenamiento vs Error de testeo\", fontsize=14)\n",
    "    axes[0].grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "    axes[0].legend(fontsize=10)\n",
    "    \n",
    "    # Y los tamaños de los arboles\n",
    "    axes[1].plot(setSizes, meanTreeSizes, color=\"red\", marker='o', linestyle='-', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel(\"Tamaño del conjunto de entrenamiento\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Cantidad de nodos del árbol\", fontsize=12)\n",
    "    axes[1].set_title(\"Cantidad de nodos del árbol respecto al\\n tamaño del conjunto de entrenamiento\", fontsize=14)\n",
    "    axes[1].grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Marcamos los tamaños adecuados en el eje X y la escala logaritmica\n",
    "    for ax in axes:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_xticks(setSizes)  \n",
    "        ax.get_xaxis().set_major_formatter(plt.ScalarFormatter()) # Esto cambia los numeros a notacion normal y no cientifica\n",
    "        ax.tick_params(axis='x', which='minor', bottom=False)     # Esconde los ticks del eje que no son relevantes\n",
    "    \n",
    "    # Y setteamos los valores del eje Y para que matcheen con nuestros resultados\n",
    "    axes[0].set_yticks(np.round(sorted(set(meanTrainingErrors + meanTestErrors)), decimals=2))\n",
    "    axes[1].set_yticks(np.round(meanTreeSizes, decimals=0))  # \n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754efc0e-2eca-4b9f-afab-6f089afdb895",
   "metadata": {},
   "source": [
    "Definimos los parametros dados como constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad374fdc-aee1-4c37-bd1d-85cf22fcebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "setCount = 20\n",
    "setSizes = [125, 250, 500, 1000, 2000, 4000]\n",
    "setSizesCount = len(setSizes)\n",
    "C = 0.78\n",
    "d = 2\n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a066e6-f64e-4316-a947-f4b7f2654fa4",
   "metadata": {},
   "source": [
    "Creamos el conjunto de test, los conjuntos de entrenamiento para cada cada tamaño, y creamos y entrenamos los clasificadores con estos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd1231-20b3-45e3-bb5a-ec5a671d5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetDiagonales = diagonales(n, d, C)\n",
    "\n",
    "trainingSetsDiagonales = generateTrainingSets(setSizes, setCount, diagonales, d, C)\n",
    "\n",
    "classifiersDiagonales = generateClassifiers(setSizesCount, setCount, trainingSetsDiagonales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c252a-5e97-49ed-8e00-c0970ac905de",
   "metadata": {},
   "source": [
    "Ahora seleccionamos un par de conjunto de entrenamiento y clasificador asociados para cada tamaño y los graficamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016ecd-fd3c-4e0c-a9a8-c4da85b78614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el primero de cada tamaño\n",
    "trainingSetsDiagonalesSample = [tSet[0] for tSet in trainingSetsDiagonales]\n",
    "classifiersDiagonalesSample  = [cSet[0] for cSet in classifiersDiagonales] \n",
    "\n",
    "plotPerSize(trainingSetsDiagonalesSample, classifiersDiagonalesSample, testSetDiagonales, setSizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa20bd-42bb-4d5a-9125-9e5f86c45241",
   "metadata": {},
   "source": [
    "Para las mismas muestras graficamos también su error y la cantidad de nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dd9249-967e-4eef-b000-1ef6caefd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los errores\n",
    "(trainingErrorsDiagonales, testErrorsDiagonales, treeSizesDiagonales) = getPerformanceStats(trainingSetsDiagonales, setSizesCount, setCount, testSetDiagonales, classifiersDiagonales)\n",
    "\n",
    "# Y plotteamos\n",
    "plotErrors(trainingErrorsDiagonales, testErrorsDiagonales, treeSizesDiagonales, setSizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e42e0-c2ce-4be6-8202-51ab31c7c731",
   "metadata": {},
   "source": [
    "## Resolución\n",
    "### Caso paralelas.\n",
    "Repetimos el procedimiento pero para el generador de paralelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da49f29-440d-4a0b-a2db-634e4faeb2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya tenemos las funciones definidas, solo falta llamarlas con el nuevo generador\n",
    "testSetParalelas = paralelas(n, d, C)\n",
    "trainingSetsParalelas = generateTrainingSets(setSizes, setCount, paralelas, d, C)\n",
    "classifiersParalelas = generateClassifiers(setSizesCount, setCount, trainingSetsParalelas)\n",
    "\n",
    "# Evaluamos el error\n",
    "(trainingErrorsParalelas, testErrorsParalelas, treeSizesParalelas) = getPerformanceStats(trainingSetsParalelas, setSizesCount, setCount, testSetParalelas, classifiersParalelas)\n",
    "\n",
    "# Obtenemos un classifier particular para cada tamaño\n",
    "trainingSetsParalelasSample = [tSet[0] for tSet in trainingSetsParalelas]\n",
    "classifiersParalelasSample  = [cSet[0] for cSet in classifiersParalelas] \n",
    "\n",
    "# Imprimimos las predicciones\n",
    "plotPerSize(trainingSetsParalelasSample, classifiersParalelasSample, testSetParalelas, setSizes)\n",
    "\n",
    "# Y los graficos de error y cantidad de nodos\n",
    "plotErrors(trainingErrorsParalelas, testErrorsParalelas, treeSizesParalelas, setSizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e24d0da-f39b-4efa-93ae-823da1141225",
   "metadata": {},
   "source": [
    "# Gráficos finales y conclusiones.\n",
    "Veamos ahora en un mismo gráfico las tasas de error para los dos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5182d-9dd0-45d8-9888-e3e07f468b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos las medias\n",
    "meanTrainingErrorsDiagonales = [np.mean(errorList) for errorList in trainingErrorsDiagonales]\n",
    "meanTestErrorsDiagonales     = [np.mean(errorList) for errorList in testErrorsDiagonales]\n",
    "meanTreeSizesDiagonales      = [np.mean(sizeList)  for sizeList in treeSizesDiagonales]\n",
    "    \n",
    "meanTrainingErrorsParalelas = [np.mean(errorList) for errorList in trainingErrorsParalelas]\n",
    "meanTestErrorsParalelas     = [np.mean(errorList) for errorList in testErrorsParalelas]\n",
    "meanTreeSizesParalelas      = [np.mean(sizeList)  for sizeList in treeSizesParalelas]\n",
    "    \n",
    "fig, axes = plt.subplots(1, 2, figsize = (18, 10))\n",
    "    \n",
    "# Graficamos error de entrenamiento contra error de testeo para diagonales\n",
    "axes[0].plot(setSizes, meanTrainingErrorsDiagonales, color=\"blue\", marker='o', linestyle='-', linewidth=2, markersize=8, label='Error de entrenamiento diagonales')\n",
    "axes[0].plot(setSizes, meanTestErrorsDiagonales, color=\"orange\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo diagonales')\n",
    "\n",
    "# Y para paralelas\n",
    "axes[0].plot(setSizes, meanTrainingErrorsParalelas, color=\"purple\", marker='o', linestyle='-', linewidth=2, markersize=8, label='Error de entrenamiento paralelas')\n",
    "axes[0].plot(setSizes, meanTestErrorsParalelas, color=\"yellow\", marker='s', linestyle='-', linewidth=2, markersize=8, label='Error de testeo paralelas')\n",
    "\n",
    "axes[0].set_xlabel(\"Tamaño del conjunto de entrenamiento\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Tasa de error\", fontsize=12)\n",
    "axes[0].set_title(\"Error de entrenamiento vs Error de testeo\", fontsize=14)\n",
    "axes[0].grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Y los tamaños de los arboles para ambos problemas\n",
    "axes[1].plot(setSizes, meanTreeSizesDiagonales, color=\"red\", marker='o', linestyle='-', linewidth=2, markersize=8)\n",
    "axes[1].plot(setSizes, meanTreeSizesParalelas, color=\"orange\", marker='o', linestyle='-', linewidth=2, markersize=8)\n",
    "\n",
    "axes[1].set_xlabel(\"Tamaño del conjunto de entrenamiento\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Cantidad de nodos del árbol\", fontsize=12)\n",
    "axes[1].set_title(\"Cantidad de nodos del árbol respecto al\\n tamaño del conjunto de entrenamiento\", fontsize=14)\n",
    "axes[1].grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "\n",
    "# Marcamos los tamaños adecuados en el eje X y la escala logaritmica\n",
    "for ax in axes:\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticks(setSizes)  \n",
    "    ax.get_xaxis().set_major_formatter(plt.ScalarFormatter()) # Esto cambia los numeros a notacion normal y no cientifica\n",
    "    ax.tick_params(axis='x', which='minor', bottom=False)     # Esconde los ticks del eje que no son relevantes\n",
    "\n",
    "# Y setteamos los valores del eje Y para que matcheen con nuestros resultados\n",
    "axes[0].set_yticks(np.round(sorted(set(meanTrainingErrorsParalelas + meanTestErrorsParalelas + meanTrainingErrorsDiagonales + meanTestErrorsDiagonales)), decimals=2))\n",
    "axes[1].set_yticks(np.round(sorted(set(meanTreeSizesParalelas + meanTreeSizesDiagonales)), decimals=0))   \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76303f80-8e2d-4f73-9918-8e8ba7e73ba1",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "Notemos que en ambos problemas el comportamiento es similar. Conforme aumentamos el tamaño del conjunto de entrenamiento los clasificadores muestran un mejor desempeño sobre el conjunto de testeo y un peor desempeño sobre el conjunto de entrenamiento. \n",
    "\n",
    "La mejora sobre la tasa de error de testeo puede atribuirse lógicamente a que, conforme aumentamos el tamaño del conjunto de entrenamiento, la muestra sobre la que entrenamos al clasificador se vuelve mas representativa de la población, por lo que el clasificador generaliza mejor.\n",
    "\n",
    "Por otro lado, lo que no nos resultó tan inmediatamente claro es por qué la tasa de error de los clasificadores empeora a mayor cantidad de datos. En un principio pensamos que sería producto de algún tipo de *post-pruning* por defecto implementado en los *DecisionTreeClassifier* de *sklearn*, pero luego de leer su documentación encontramos que no se realiza ningún tipo de poda sobre el árbol al menos que sea explícitamente solicitado.\n",
    "\n",
    "Al notar esto, consideramos otra explicación que relaciona el aumento de la tasa de error de entrenamiento con el decrecimiento en la cantidad de nodos de los árboles. Recordemos que la fórmula de ganancia de información utilizada, dado un conjunto de datos *S* y un atributo *A*, es\n",
    "\n",
    "$$\n",
    "\\operatorname{Gain}(S,A) = \\operatorname{Entropy}(S)- \\sum_{v \\in \\operatorname{Values}(A)}\\bigg( \\frac{|S_v|}{|S|} \\cdot \\operatorname{Entropy}(S_v)\\bigg).\n",
    "$$\n",
    "\n",
    "Lo importante en este caso es que la sumatoria está dividida por $|S|$. Nuestra explicación para el comportamiento de los clasificadores es que, a valores pequeños de $|S|$, en el entrenamiento quizas se realicen *splits* que no son significativos a nivel poblacional pero si lo son a nivel del conjunto de entrenamiento. En otros términos, puede que producto de la varianza en una muestra pequeña de datos se encuentren *splits* con valores suficientemente altos de ganancia de información pero que no se condicen con una división real de los datos en la población. Básicamente, el árbol esta siendo sobreajustado al conjunto de entrenamiento, aprendiendo parámetros que sí diferencian a las clases para nuestra pequeña muestra pero que no se replican en la población.\n",
    "\n",
    "En cambio, cuando $|S|$ aumenta, la varianza muestral disminuye y estos *splits* que en conjuntos de entrenamiento pequeños tienen una ganancia de información lo suficientemente alta dejan de tenerla, pues los valores aislados se compensan. Y justamente, como se realizan menos *splits*, tiene sentido que la cantidad de nodos del árbol disminuya.\n",
    "\n",
    "Un árbol mas pequeño es un árbol mas general, lo que explica que el desempeño sobre el conjunto de entrenamiento empeore y el desempeño sobre el conjunto de testeo aumente cuando disminuye la cantidad de nodos. El árbol generado está aprendiendo menos detalles particulares que eran producto de la varianza, pues ya no encuentra ganancia de información en realizar ciertas divisiones que son relevantes solamente en esas muestras pequeñas.\n",
    "\n",
    "De alguna manera, los valores de error que se obtenían para los clasificadores entrenados sobre conjuntos pequeños no eran \"realistas\". Una tasa de error tan pequeña solo podría explicarse por un alto nivel de sobreajuste. El que las tasas de error tiendan a un mismo valor conforme aumenta el tamaño del conjunto de entrenamiento es una señal de que se está generalizando mejor. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
